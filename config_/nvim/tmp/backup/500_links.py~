import sys
import os
import re
import urllib.request as req
from bs4 import BeautifulSoup as lijepa_supa

if 2 != len(sys.argv):
    sys.exit(1)

separator = "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-"
url = 'https://techiedelight.quora.com/500-Data-Structures-and-Algorithms-practice-problems-and-their-solutions?__filter__&__nsrc__=2&__snid3__=1594232728&amp;share=1'
page = req.urlopen(url)
html_content = page.read()
soup = lijepa_supa(html_content, "html5lib")

b_patt = re.compile('<b>([^<]+)<\/b>')
a_patt = re.compile('<a(?:.*?)href=\"([^\"]+)\"(?:[^>]+)>([^<]+)<')

o_file = open(sys.argv[1], "w+")

for s in soup.find_all(['b', 'a']):
    b_mtc = b_patt.search(str(s))
    a_mtc = a_patt.search(str(s))
    if None != b_mtc:
        o_file.write("%s\n%s\n%s\n" % (separator, b_mtc.group(1), separator))
    elif None != a_mtc and "#" != a_mtc.group(1):
        o_file.write("\t%s: \'%s\'\n" % (a_mtc.group(2), a_mtc.group(1)))

o_file.close()
